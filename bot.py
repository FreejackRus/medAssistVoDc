import os
import re
import pandas as pd
from dotenv import load_dotenv
from typing import List, Tuple, Optional
# LangChain + Hugging Face
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_huggingface import HuggingFacePipeline
# –î–æ–∫—É–º–µ–Ω—Ç—ã –∏ —Ä–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
from langchain_community.document_loaders import DirectoryLoader
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
# Transformers –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()


class MedicalAssistant:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
        self.db = self.init_knowledge_base()
        self.llm = self.load_phi_model()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )

    def load_phi_model(self, model_name: str = "Intelligent-Internet/II-Medical-8B-1706") -> HuggingFacePipeline:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            device_map="auto",
            torch_dtype="auto",
            trust_remote_code=True
        )
        pipe = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            max_new_tokens=2048,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –±–æ–ª–µ–µ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            temperature=0.5,       # –°–Ω–∏–∂–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –¥–ª—è –±–æ–ª—å—à–µ–π –ª–æ–≥–∏—á–Ω–æ—Å—Ç–∏
            top_p=0.95,
            repetition_penalty=1.2,
            return_full_text=False
        )
        return HuggingFacePipeline(pipeline=pipe)

    def load_services_documents(self) -> List[Document]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —É—Å–ª—É–≥–∏ –∏–∑ Excel (—Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å ID –∏ –ù–∞–∑–≤–∞–Ω–∏–µ)"""
        try:
            df = pd.read_excel("docs/services.xlsx")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            required_columns = ["ID", "–ù–∞–∑–≤–∞–Ω–∏–µ"]
            if not all(col in df.columns for col in required_columns):
                raise ValueError(f"–í —Ñ–∞–π–ª–µ services.xlsx –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∏: {required_columns}")

            documents = []
            for _, row in df.iterrows():
                service_id = str(row["ID"])
                service_name = str(row["–ù–∞–∑–≤–∞–Ω–∏–µ"])

                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                content = f"–£—Å–ª—É–≥–∞ {service_id}: {service_name}"

                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–ª—è)
                metadata = {
                    "source": "services",
                    "id": service_id,
                    "name": service_name,
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏–ø –¥–ª—è —è—Å–Ω–æ—Å—Ç–∏
                    "type": "medical_service"
                }

                documents.append(Document(page_content=content, metadata=metadata))

            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(documents)} —É—Å–ª—É–≥ –∏–∑ —Ñ–∞–π–ª–∞ services.xlsx")
            return documents

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —É—Å–ª—É–≥: {str(e)}")
            return []

    def load_mkb10(self) -> List[Document]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ú–ö–ë-10"""
        try:
            df = pd.read_csv("docs/mkb10.csv", on_bad_lines='skip', header=None)
            documents = []
            for _, row in df.iterrows():
                if len(row) < 4:
                    continue
                code = str(row[2]).strip() if not pd.isna(row[2]) else ""
                name = str(row[3]).strip() if not pd.isna(row[3]) else ""
                if code and name:
                    content = f"–ö–æ–¥: {code}, –ù–∞–∑–≤–∞–Ω–∏–µ: {name}"
                    metadata = {"source": "mkb10", "code": code}
                    documents.append(Document(page_content=content, metadata=metadata))
            return documents
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ú–ö–ë-10: {str(e)}")
            return []

    def process_clinical_docs(self, docs: List[Document]) -> List[Document]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        processed_docs = []
        for doc in docs:
            try:
                doc.metadata["source"] = "clinical"
                chunks = self.text_splitter.split_documents([doc])
                processed_docs.extend(chunks)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(e)}")
        return processed_docs

    def init_knowledge_base(self) -> FAISS:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        documents = []
        # –ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
        try:
            clinical_loader = DirectoryLoader("docs/", glob="clinical_*.pdf")
            clinical_docs = clinical_loader.load()
            documents.extend(self.process_clinical_docs(clinical_docs))
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {str(e)}")
        # –ú–ö–ë-10
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –ú–ö–ë-10...")
        documents.extend(self.load_mkb10())
        # –£—Å–ª—É–≥–∏
        print("–ó–∞–≥—Ä—É–∑–∫–∞ —É—Å–ª—É–≥...")
        documents.extend(self.load_services_documents())
        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        print("–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã...")
        try:
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            )
            return FAISS.from_documents(documents, embeddings)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã: {str(e)}")
            raise

    def find_mkb10(self, query: str) -> Optional[Document]:
        """–ü–æ–∏—Å–∫ –¥–∏–∞–≥–Ω–æ–∑–∞ –ø–æ –ú–ö–ë-10"""
        try:
            # –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É
            if re.match(r"^[A-Z]\d{2}(\.\d)?$", query.upper()):
                doc = self.find_mkb10_exact(query.upper())
                if doc:
                    return doc
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
            docs = self.safe_similarity_search(
                query,
                k=1,
                source_filter="mkb10"
            )
            return docs[0] if docs else None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–∏–∞–≥–Ω–æ–∑–∞: {str(e)}")
            return None

    def find_mkb10_exact(self, code: str) -> Optional[Document]:
        """–¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É –ú–ö–ë-10"""
        try:
            for doc_id in self.db.index_to_docstore_id.values():
                doc = self.db.docstore.search(doc_id)
                if isinstance(doc, Document) and doc.metadata.get("code") == code:
                    return doc
                elif isinstance(doc, dict) and doc.get("metadata", {}).get("code") == code:
                    return Document(
                        page_content=doc.get("page_content", ""),
                        metadata=doc.get("metadata", {})
                    )
            return None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ú–ö–ë: {str(e)}")
            return None

    def safe_similarity_search(self, query: str, k: int = 3, source_filter: Optional[str] = None, fetch_k: int = 50) -> List[Document]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–æ–∏—Å–∫ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            all_docs = []
            for doc_id in self.db.index_to_docstore_id.values():
                doc = self.db.docstore.search(doc_id)
                all_docs.append(doc)

            filtered_docs = []
            for doc in all_docs:
                if isinstance(doc, Document):
                    if not source_filter or doc.metadata.get("source") == source_filter:
                        filtered_docs.append(doc)
                elif isinstance(doc, dict):
                    if not source_filter or doc.get("metadata", {}).get("source") == source_filter:
                        filtered_docs.append(
                            Document(
                                page_content=doc.get("page_content", ""),
                                metadata=doc.get("metadata", {})
                            )
                        )

            if filtered_docs:
                embeddings = HuggingFaceEmbeddings(
                    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
                )
                temp_db = FAISS.from_documents(filtered_docs, embeddings)
                return temp_db.similarity_search(query[:300], k=k, fetch_k=fetch_k)
            return []
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {str(e)}")
            return []

    def find_relevant_services(self, query: str, k: Optional[int] = None) -> List[Document]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —É—Å–ª—É–≥–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º (k=None –¥–ª—è –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞)"""
        try:
            services = self.safe_similarity_search(
                query,
                k=k or 50,
                source_filter="services",
                fetch_k=(k or 50) * 3
            )

            seen_ids = set()
            unique_services = []
            for service in services:
                service_id = service.metadata.get("id")
                if service_id and service_id not in seen_ids:
                    seen_ids.add(service_id)
                    unique_services.append(service)
            return unique_services
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —É—Å–ª—É–≥: {str(e)}")
            return []

    def find_clinical_context(self, query: str, k: int = 1) -> str:
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        try:
            docs = self.safe_similarity_search(
                query,
                k=k,
                source_filter="clinical"
            )
            return docs[0].page_content[:1000] + "..." if docs else "–ù–µ—Ç –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {str(e)}")
            return "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"

    def format_services(self, services: List[Document]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —É—Å–ª—É–≥"""
        try:
            if not services:
                return "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —É—Å–ª—É–≥"
            service_list = []
            for doc in services:
                if isinstance(doc, Document) and doc.metadata.get("id"):
                    service_info = f"- ID {doc.metadata['id']}: {doc.metadata['name']}"
                    if doc.metadata.get("category"):
                        service_info += f" (–∫–∞—Ç–µ–≥–æ—Ä–∏—è: {doc.metadata['category']})"
                    if doc.metadata.get("description"):
                        service_info += f"\n  –û–ø–∏—Å–∞–Ω–∏–µ: {doc.metadata['description']}"
                    service_list.append(service_info)
            return "\n".join(service_list)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —É—Å–ª—É–≥: {str(e)}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ —É—Å–ª—É–≥"

    def generate_response(self, diagnosis: str, services: List[Document], clinical_context: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –∏ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏"""
        try:
            service_ids = [s.metadata['id'] for s in services if s.metadata.get('id')]
            services_prompt = ", ".join(service_ids) if service_ids else "–Ω–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —É—Å–ª—É–≥"

            prompt = f"""
–í—ã ‚Äî –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –¥–∏–∞–≥–Ω–æ–∑–∞ –∏ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å—Ñ–æ—Ä–º–∏—Ä—É–π—Ç–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –ª–µ—á–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —É—Å–ª—É–≥–∏ —Å –∏—Ö ID. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω, –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω –∏ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –æ–∫–∞–∑–∞–Ω–∏—è –ø–æ–º–æ—â–∏.

–î–∏–∞–≥–Ω–æ–∑: {diagnosis}
–î–æ—Å—Ç—É–ø–Ω—ã–µ —É—Å–ª—É–≥–∏ (ID): {services_prompt}

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
### –ü–æ–¥—Ä–æ–±–Ω—ã–π –ê–ª–≥–æ—Ä–∏—Ç–º –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –õ–µ—á–µ–Ω–∏—è {diagnosis.split(':')[-1].strip()}

#### I. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞—Ü–∏–µ–Ω—Ç–∞
- –ö—Ä–∞—Ç–∫–∞—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –¥–∏–∞–≥–Ω–æ–∑–∞
- –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –∏ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞
- –û—Å–Ω–æ–≤–Ω—ã–µ —Å–∏–º–ø—Ç–æ–º—ã –∏ –ø—Ä–∏–∑–Ω–∞–∫–∏

#### II. –≠—Ç–∞–ø—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
1. **–ü–µ—Ä–≤–∏—á–Ω–æ–µ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ**:
   - –î–µ–π—Å—Ç–≤–∏—è –≤—Ä–∞—á–∞
   - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (ID —É—Å–ª—É–≥)
   - –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
2. **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏**:
   - –¶–µ–ª–∏ –∏ –∑–∞–¥–∞—á–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
   - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã (ID —É—Å–ª—É–≥)
   - –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è

#### III. –î–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
- –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç–æ–ª–æ–≥–∏–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
- –ü—Ä–∏–∑–Ω–∞–∫–∏, –æ—Ç–ª–∏—á–∞—é—â–∏–µ —Ç–µ–∫—É—â–∏–π –¥–∏–∞–≥–Ω–æ–∑
- –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã

#### IV. –¢–∞–∫—Ç–∏–∫–∞ –ª–µ—á–µ–Ω–∏—è
1. **–ù–µ–º–µ–¥–∏–∫–∞–º–µ–Ω—Ç–æ–∑–Ω–∞—è —Ç–µ—Ä–∞–ø–∏—è**:
   - –û–±—Ä–∞–∑ –∂–∏–∑–Ω–∏, –¥–∏–µ—Ç–∞, —Ñ–∏–∑–∏—á–µ—Å–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
2. **–ú–µ–¥–∏–∫–∞–º–µ–Ω—Ç–æ–∑–Ω–∞—è —Ç–µ—Ä–∞–ø–∏—è**:
   - –ü—Ä–µ–ø–∞—Ä–∞—Ç—ã, –¥–æ–∑–∏—Ä–æ–≤–∫–∏, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
3. **–ü—Ä–æ—Ü–µ–¥—É—Ä—ã –∏ –æ–ø–µ—Ä–∞—Ü–∏–∏**:
   - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —É—Å–ª—É–≥–∏ (ID)
   - –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞, –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, —Ä–µ–∞–±–∏–ª–∏—Ç–∞—Ü–∏—è
4. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏**
   - –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É–ª—É—á—à–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
   - –ú–µ—Ç–æ–¥—ã –æ—Ü–µ–Ω–∫–∏

#### V. –†–µ–∞–±–∏–ª–∏—Ç–∞—Ü–∏—è –∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é
- –ü–ª–∞–Ω –Ω–∞–±–ª—é–¥–µ–Ω–∏—è —É —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤
- –ü—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ä—ã

#### VI. –û—Å–æ–±—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—Ä–∏ –æ—Å–ª–æ–∂–Ω–µ–Ω–∏—è—Ö
- –í–∞—Ä–∏–∞–Ω—Ç—ã –≤—Ç–æ—Ä–∏—á–Ω–æ–π –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∏
- –°–æ–≤–µ—Ç—ã –ø–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—é —Å –¥—Ä—É–≥–∏–º–∏ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è–º–∏

#### VII. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
- –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
- –ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞–º–∏

–°—Ñ–æ—Ä–º–∏—Ä—É–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –ª–µ—á–µ–Ω–∏—è —Å —É–∫–∞–∑–∞–Ω–∏–µ–º ID —É—Å–ª—É–≥
"""

            response = self.llm.invoke(prompt)
            services_list = self.format_services(services)
            final_response = f"""
### –ü–æ–¥—Ä–æ–±–Ω—ã–π –ê–ª–≥–æ—Ä–∏—Ç–º –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –õ–µ—á–µ–Ω–∏—è {diagnosis.split(':')[-1].strip()}
{response}

"""
            return final_response
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑-–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏"

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
        try:
            print("–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –ë—É–¥—É—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω—ã –≤—Å–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —É—Å–ª—É–≥–∏.")
            print("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å:")
            while True:
                query = input("\n–í–≤–µ–¥–∏—Ç–µ –¥–∏–∞–≥–Ω–æ–∑ –∏–ª–∏ –∫–æ–¥ –ú–ö–ë-10 (exit/quit/–≤—ã–π—Ç–∏): ").strip()
                if query.lower() in ["exit", "–≤—ã–π—Ç–∏", "quit"]:
                    break
                print("\nüîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞...")
                diagnosis_doc = self.find_mkb10(query)
                if not diagnosis_doc:
                    print("‚ùå –î–∏–∞–≥–Ω–æ–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    continue
                diagnosis = diagnosis_doc.page_content
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω –¥–∏–∞–≥–Ω–æ–∑: {diagnosis}")
                services = self.find_relevant_services(diagnosis)
                if not services:
                    print("‚ö†Ô∏è –£—Å–ª—É–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    continue
                print(f"üîß –ù–∞–π–¥–µ–Ω–æ {len(services)} —É—Å–ª—É–≥")
                clinical_context = self.find_clinical_context(diagnosis)
                print("\nüß† –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
                response = self.generate_response(diagnosis, services, clinical_context)
                print("\nü§ñ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n", response)
        except KeyboardInterrupt:
            print("\n–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
        except Exception as e:
            print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")


if __name__ == '__main__':
    try:
        assistant = MedicalAssistant()
        assistant.run()
    except Exception as e:
        print(f"–§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ: {str(e)}")
    finally:
        input("–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")